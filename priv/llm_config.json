{
  "llm_config": {
    "created_at": "2025-12-14T09:43:50.349470Z",
    "endpoint": "http://host.docker.internal:1234/v1/chat/completions",
    "max_tokens": 2000,
    "model": "deepseek-coder-v2-lite-instruct",
    "provider": "lm_studio",
    "streaming": true,
    "temperature": 0.7,
    "timeout": 30000,
    "version": "1.0"
  }
}